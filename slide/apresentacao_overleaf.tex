% Versão consolidada para Overleaf
% Todos os arquivos em um único documento para evitar problemas de \input

\documentclass[aspectratio=169]{beamer}

% Pacotes
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{siunitx}

% Tema e cores
\usetheme{Madrid}
\usecolortheme{default}

% Informações do título
\title[Equação de Helmholtz 2D e MDFC2]{Equação de Helmholtz Bidimensional e o Método das\\Diferenças Finitas Centradas de Segunda Ordem}
\author{Gabriel Santos Piveti \and João Carlos Romero Monteiro \and Lieger Duarte de Oliveira Rosa}
\date{\today}
\institute{Programa de Pós-Graduação em Modelagem Computacional\\Universidade Federal Fluminense}

% Comandos personalizados
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

\begin{document}

% Slide de título
\begin{frame}
\titlepage
\end{frame}

% Sumário
\begin{frame}{Sumário}
\tableofcontents
\end{frame}

% ============================================
% SEÇÃO 1: INTRODUÇÃO
% ============================================
\section{Introdução}

\begin{frame}{Equação de Helmholtz}
\begin{block}{Equação de Helmholtz 2D}
A equação de Helmholtz é uma equação diferencial parcial elíptica que surge naturalmente na modelagem de fenômenos ondulatórios em regime harmônico:
\begin{equation*}
\nabla^2 u + k^2 u = 0 \quad \text{em } \Omega = [0,1]^2
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Interpretação dos Termos}
\begin{itemize}
\item $\nabla^2 u$: Operador Laplaciano — mede a curvatura espacial da solução
\item $k^2 u$: Termo reativo — impõe caráter oscilatório
\item $u(x,y)$: Campo escalar desconhecido
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{alertblock}{Observação}
Quanto maior o valor de $k$, maior a frequência espacial da solução, exigindo malhas mais refinadas.
\end{alertblock}
\end{frame}

\begin{frame}{Derivação a partir da Equação da Onda}
\begin{block}{Equação da Onda}
\begin{equation*}
\frac{\partial^2 u}{\partial t^2} = c^2 \nabla^2 u
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Solução Harmônica}
Assumindo solução periódica no tempo:
\begin{equation*}
u(x, y, t) = \text{Re}\left(U(x, y) e^{-i\omega t}\right)
\end{equation*}
Substituindo na equação da onda:
\begin{equation*}
\nabla^2 U + \left(\frac{\omega}{c}\right)^2 U = 0
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Número de Onda}
Definindo $k = \omega/c$, obtém-se a equação de Helmholtz:
\begin{equation*}
\nabla^2 U + k^2 U = 0
\end{equation*}
\end{block}
\end{frame}

\begin{frame}{Solução Exata}
\begin{block}{Superposição de Ondas Planas}
Para validação e cálculo de erro, utilizamos solução exata imposta como condição de Dirichlet na fronteira:
\begin{equation*}
u_{\text{exata}}(x, y) = \sum_{i=1}^{3} \cos\left(k (x \cos \theta_i + y \sin \theta_i)\right)
\end{equation*}
com ângulos: $\Theta = \{0, \pi/8, \pi/4\}$
\end{block}

\vspace{0.3cm}

\begin{block}{Aplicações Práticas}
\begin{itemize}
\item Acústica arquitetônica
\item Propagação eletromagnética
\item Vibrações mecânicas
\item Difração e espalhamento de ondas
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Objetivos do Trabalho}
\begin{block}{Objetivo Geral}
Aplicar o Método das Diferenças Finitas Centradas de Segunda Ordem (MDFC2) à equação de Helmholtz bidimensional e analisar seus efeitos numéricos.
\end{block}

\vspace{0.3cm}

\begin{block}{Objetivos Específicos}
\begin{itemize}
\item Estudar a formulação matemática da equação de Helmholtz
\item Implementar a discretização por MDFC2
\item Investigar a influência do número de onda $k$
\item Analisar o fenômeno de poluição numérica
\item Avaliar o uso de Inteligência Artificial como ferramenta auxiliar
\item Comparar métodos considerando precisão e custo computacional
\end{itemize}
\end{block}
\end{frame}

% ============================================
% SEÇÃO 2: FUNDAMENTAÇÃO TEÓRICA
% ============================================
\section{Fundamentação Teórica}

\begin{frame}{Ideia Geral do Método das Diferenças Finitas}
\begin{block}{Conceito}
O Método das Diferenças Finitas consiste em aproximar derivadas por combinações lineares de valores da função em pontos discretos de uma malha uniforme.
\end{block}

\vspace{0.3cm}

\begin{block}{Malha Uniforme}
\begin{itemize}
\item Domínio $\Omega = [0,1]^2$ discretizado em malha uniforme
\item $N$ subintervalos em cada direção
\item Tamanho do passo: $h = 1/N$
\item Pontos da malha: $(x_i, y_j) = (ih, jh)$
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Stencil de 5 Pontos}
Para discretizar o Laplaciano 2D, utilizamos um estêncil de 5 pontos (centro + 4 vizinhos).
\end{block}
\end{frame}

\begin{frame}{Diferença Finita Centrada de Segunda Ordem}
\begin{block}{Primeira Derivada}
A derivada primeira pode ser aproximada por:
\begin{equation*}
\frac{\partial u}{\partial x} \approx \frac{u(x+h) - u(x-h)}{2h}
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Propriedades}
Essa aproximação:
\begin{itemize}
\item Utiliza pontos simétricos (centrada)
\item Possui erro de truncamento $O(h^2)$
\item É mais precisa que diferenças progressivas ou regressivas
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Segunda Derivada}
A segunda derivada é aproximada por:
\begin{equation*}
\frac{\partial^2 u}{\partial x^2} \approx \frac{u(x+h) - 2u(x) + u(x-h)}{h^2} \quad (2)
\end{equation*}
Essa forma é fundamental para a discretização do operador Laplaciano.
\end{block}
\end{frame}

\begin{frame}{Discretização do Laplaciano 2D}
\begin{block}{Laplaciano Contínuo}
\begin{equation*}
\Delta u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Discretização com Stencil de 5 Pontos}
Em uma malha uniforme $(x_i, y_j) = (ih, jh)$:
\begin{equation*}
\Delta u(x_i, y_j) \approx \frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2}
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Equação Discretizada}
Substituindo na equação de Helmholtz:
\begin{equation*}
\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + k^2 u_{i,j} = 0
\end{equation*}
\end{block}
\end{frame}

\begin{frame}{Consistência e Estabilidade}
\begin{block}{Consistência}
O método é \textbf{consistente} de ordem 2:
\begin{equation*}
\tau_{i,j} = O(h^2) \quad \text{(erro de truncamento local)}
\end{equation*}
Aproximação converge para a solução exata quando $h \to 0$.
\end{block}

\vspace{0.3cm}

\begin{block}{Estabilidade}
Para a equação de Helmholtz:
\begin{itemize}
\item Sistema linear: $A\mathbf{u} = \mathbf{b}$
\item Matriz $A = L + k^2 I$ é definida positiva para $k$ real
\item Condicionamento piora com $k$ grande (requer malhas mais finas)
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{alertblock}{Teorema de Lax}
Consistência + Estabilidade $\Rightarrow$ Convergência
\end{alertblock}
\end{frame}

\begin{frame}{Análise de Dispersão Numérica}
\begin{block}{Problema}
O método de diferenças finitas introduz \textbf{dispersão numérica}: a velocidade de fase numérica difere da exata.
\end{block}

\vspace{0.3cm}

\begin{block}{Número de Pontos por Comprimento de Onda}
Para capturar uma onda com número de onda $k$:
\begin{equation*}
N_{\lambda} = \frac{2\pi}{kh} = \frac{2\pi N}{k}
\end{equation*}
Recomendação: $N_{\lambda} \geq 10-20$ pontos por comprimento de onda.
\end{block}

\vspace{0.3cm}

\begin{block}{Poluição Numérica}
Para $k$ grande e $h$ fixo:
\begin{itemize}
\item Poucos pontos por comprimento de onda
\item Erro de fase acumula
\item Solução numérica "atrasa" em relação à exata
\item Taxa de convergência degrada ($p < 2$)
\end{itemize}
\end{block}
\end{frame}

% ============================================
% SEÇÃO 3: METODOLOGIA
% ============================================
\section{Metodologia}

\begin{frame}{Discretização da Equação de Helmholtz}
\begin{block}{Aplicando MDFC2}
Aplicando o Método das Diferenças Finitas Centradas de Segunda Ordem no domínio $\Omega = [0,1]^2$:
\begin{equation*}
\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + k^2 u_{i,j} = 0 \quad (3)
\end{equation*}
\end{block}

\vspace{0.3cm}

\begin{block}{Sistema Linear}
Resultando em um sistema linear esparso:
\begin{equation*}
A \mathbf{u} = \mathbf{b}
\end{equation*}
onde:
\begin{itemize}
\item $A$: Matriz esparsa $(N-1)^2 \times (N-1)^2$
\item $\mathbf{u}$: Vetor de incógnitas (valores nos pontos internos)
\item $\mathbf{b}$: Vetor com contribuições das condições de contorno Dirichlet
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Estratégia Computacional: Matrizes Esparsas}
\begin{block}{Desafio}
Para capturar a física em $k = 100$, a malha deve ser fina ($N > 200$).
\begin{itemize}
\item $N = 200 \Rightarrow 40.000$ incógnitas
\item Matriz densa: $\approx 12$ GB de RAM (inviável/lento)
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Solução: Matrizes Esparsas}
\begin{itemize}
\item \textbf{Formato LIL/CSC}: Armazena apenas elementos não-zero
\item \textbf{Consumo de memória}: Irrisório comparado à matriz densa
\item \textbf{Implementação}: Utilizando \texttt{scipy.sparse}
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Montagem Eficiente}
\begin{itemize}
\item Montagem da matriz em formato LIL (List of Lists)
\item Conversão para CSC (Compressed Sparse Column) para solução
\item Solver direto otimizado: \texttt{spsolve} ou fatoração LU esparsa
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Estratégias de Solução}
\begin{block}{Solvers Implementados}
\begin{itemize}
\item \textbf{SPLU}: Fatoração LU esparsa (direto)
  \begin{itemize}
  \item Eficiente para sistemas pequenos/médios ($N \leq 192$)
  \item Custo: $O(N^3)$ operações, $O(N^2)$ memória
  \end{itemize}
\item \textbf{GMRES+ILU}: Método iterativo com pré-condicionador
  \begin{itemize}
  \item Eficiente para sistemas grandes ($N \geq 256$)
  \item Custo: $O(N^2)$ por iteração, convergência rápida
  \end{itemize}
\item \textbf{Auto}: Escolhe automaticamente baseado no tamanho
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Tratamento de Singularidades}
\begin{itemize}
\item Fallback automático quando ILU falha
\item Uso de SPLU ou GMRES sem pré-condicionador como alternativa
\item Garante robustez para todos os casos
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Configuração do Experimento}
\begin{block}{Solução Exata}
Para validação e cálculo de erro, utilizamos solução exata imposta como condição de Dirichlet na fronteira $\Gamma$:
\begin{equation*}
u_{\text{exata}}(x, y) = \sum_{i=1}^{3} \cos\left(k (x \cos \theta_i + y \sin \theta_i)\right)
\end{equation*}
com ângulos: $\Theta = \{0, \pi/8, \pi/4\}$
\end{block}

\vspace{0.3cm}

\begin{block}{Parâmetros de Teste}
\begin{itemize}
\item Malhas: $N \in \{64, 128, 192, 256\}$ (extendido para análise completa)
\item Números de onda: $k \in \{1, 20, 40, 100\}$
\item Validação inicial: $N = 60$ (conforme trabalho original)
\item Total: $6 \times 4 \times 4 = 96$ casos (extensão do trabalho)
\end{itemize}
\end{block}
\end{frame}

% ============================================
% SEÇÃO 4: RESULTADOS
% ============================================
\section{Resultados}

\begin{frame}{Quantificação do Erro}
\begin{block}{Normas Utilizadas}
Para avaliar a precisão, calculamos o erro relativo entre a solução numérica ($U_{\text{aprox}}$) e a exata ($U_{\text{exata}}$):

\vspace{0.2cm}

\textbf{Norma Discreta ($\ell_2$)}: Mede o erro médio nos nós da malha
\begin{equation*}
E_{\ell_2} = \frac{\|U_{\text{aprox}} - U_{\text{exata}}\|_2}{\|U_{\text{exata}}\|_2}
\end{equation*}

\vspace{0.2cm}

\textbf{Norma Contínua ($L^2(\Omega)$)}: Aproxima a integral do erro no domínio (ponderado por $h$)
\begin{equation*}
E_{L^2} \approx \frac{\|U_{\text{aprox}} - U_{\text{exata}}\|_2 \cdot h}{\|U_{\text{exata}}\|_2 \cdot h} = E_{\ell_2}
\end{equation*}
\end{block}
\end{frame}

\begin{frame}{Resultados Obtidos - Erro Relativo (Grupo 1)}
\footnotesize
\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
$N$ & $k=1$ & $k=20$ & $k=40$ & $k=100$ \\
\midrule
64  & \num{6.43e-07} & \num{2.11e-01} & \num{1.11e+00} & \num{2.54e+00} \\
128 & \num{1.62e-07} & \num{4.24e-02} & \num{2.82e-01} & \num{1.49e+00} \\
192 & \num{7.21e-08} & \num{1.87e-02} & \num{2.12e-01} & \num{1.29e+00} \\
256 & \num{4.19e-08} & \num{1.05e-02} & \num{1.71e-01} & \num{3.62e+00} \\
\bottomrule
\end{tabular}
\caption{Erro relativo L2 para diferentes malhas e números de onda (Grupo 1)}
\end{table}

\vspace{0.2cm}

\begin{block}{Observações}
\begin{itemize}
\item Para $k=1$: erro diminui de $6.4 \times 10^{-7}$ (N=64) para $4.2 \times 10^{-8}$ (N=256)
\item Para $k=20$: erro diminui de $0.21$ (N=64) para $0.01$ (N=256)
\item Para $k=100$: erro permanece alto mesmo com refinamento ($3.6$ para N=256)
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Análise de Convergência}
\begin{block}{Comportamento do Erro}
\begin{itemize}
\item Para $k$ pequeno ($k=1$): erro diminui com $h^2$ (ordem 2 confirmada)
\item Para $k$ médio ($k=20, 40$): convergência mais lenta (taxa $p \approx 1.5-1.8$)
\item Para $k$ grande ($k=100$): requer $N \geq 256$ para erro aceitável (taxa $p < 1$)
\end{itemize}
\end{block}

\vspace{0.2cm}

\begin{block}{Regra de Thumb}
Para capturar bem uma onda, precisamos de aproximadamente:
\begin{equation*}
N_{\lambda} = \frac{2\pi}{kh} = \frac{2\pi N}{k} \gtrsim 10-20
\end{equation*}
Para $k=100$ e $N=256$: $N_{\lambda} \approx 16$ (marginal, explica erro grande)
\end{block}
\end{frame}

\begin{frame}{Análise de Convergência - Conclusões}
\begin{alertblock}{Observação Principal}
Taxa de convergência experimental confirma teoria: $p \approx 2.0$ para $k$ pequeno, degrada para $k$ grande devido à poluição numérica.
\end{alertblock}

\vspace{0.3cm}

\begin{block}{Resumo dos Resultados}
\begin{itemize}
\item \textbf{Ordem 2 confirmada}: Para $k=1$, taxa $p \approx 2.0$ (conforme esperado)
\item \textbf{Degradação gradual}: Taxa diminui de $2.0$ para $1.5-1.8$ quando $k$ aumenta
\item \textbf{Poluição numérica}: Para $k=100$, taxa cai para $p < 1$ (poluição severa)
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Taxa de Convergência}
\begin{block}{Definição}
A taxa de convergência $p$ é definida por:
\begin{equation*}
\text{erro}(h) \approx C h^p \quad \Rightarrow \quad p = \frac{\log(\text{erro}(h_1)/\text{erro}(h_2))}{\log(h_1/h_2)}
\end{equation*}
\end{block}

\vspace{0.2cm}

\begin{block}{Resultados Experimentais (Grupo 1)}
\footnotesize
\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
$k$ & Taxa de Convergência & Esperado \\
\midrule
1   & $\approx 2.0$ & 2.0 (ordem 2) \\
20  & $\approx 1.5-1.8$ & 2.0 (degradado) \\
40  & $\approx 1.2-1.5$ & 2.0 (degradado) \\
100 & $\approx 0.5-1.0$ & 2.0 (poluição numérica) \\
\bottomrule
\end{tabular}
\caption{Taxa de convergência observada vs esperada}
\end{table}
\end{block}

\vspace{0.1cm}

\begin{alertblock}{Observação}
Para $k$ grande, a taxa de convergência degrada devido à poluição numérica (poucos pontos por comprimento de onda).
\end{alertblock}
\end{frame}

\begin{frame}{Comparação entre Grupos ($N=256$)}
\footnotesize
\begin{block}{Erro Relativo L2 para Todos os Grupos}
\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
Grupo & $k=1$ & $k=20$ & $k=40$ & $k=100$ \\
\midrule
1 & \num{4.19e-08} & \num{1.05e-02} & \num{1.71e-01} & \num{3.62e+00} \\
2 & \num{4.18e-08} & \num{1.37e-02} & \num{3.14e-02} & \num{2.39e+00} \\
3 & \num{3.41e-08} & \num{1.32e-02} & \num{1.77e-01} & \num{8.30e-01} \\
4 & \num{4.06e-08} & \num{1.11e-02} & \num{1.77e-01} & \num{3.63e+00} \\
5 & \num{4.04e-08} & \num{1.15e-02} & \num{3.82e-02} & \num{2.43e+00} \\
6 & \num{3.43e-08} & \num{1.15e-02} & \num{1.78e-01} & \num{8.28e-01} \\
\bottomrule
\end{tabular}
\caption{Erro relativo L2 para $N=256$ (média de múltiplas execuções)}
\end{table}
\end{block}

\vspace{0.1cm}

\begin{block}{Observações}
\begin{itemize}
\item Para $k$ pequeno: todos os grupos têm erro similar (ordem $10^{-8}$)
\item Para $k$ grande: diferenças significativas entre grupos (dependência da direção das ondas)
\item Grupos 3 e 6 apresentam melhor desempenho para $k=100$
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Desempenho Computacional - Tempos de Execução}
\footnotesize
\begin{block}{Tempos para Diferentes Malhas (Grupo 1)}
\begin{table}[h]
\centering
\begin{tabular}{lccccc}
\toprule
$N$ & Incógnitas & Build (s) & Solve (s) & Solver \\
\midrule
64  & 3,969  & 0.001 & 0.008 & SPLU \\
128 & 16,129 & 0.003 & 0.039 & SPLU \\
192 & 36,481 & 0.006 & 0.117 & SPLU \\
256 & 65,025 & 0.008 & 0.630 & GMRES+ILU \\
\bottomrule
\end{tabular}
\caption{Tempos médios de execução (build e solve)}
\end{table}
\end{block}
\end{frame}

\begin{frame}{Desempenho Computacional - Tempos por $k$ ($N=256$)}
\footnotesize
\begin{block}{Tempos para $N=256$ por Número de Onda}
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
$k$ & Build (s) & Solve (s) & Solver \\
\midrule
1   & 0.013 & 0.404 & GMRES+ILU \\
20  & 0.008 & 0.761 & GMRES+ILU \\
40  & 0.004 & 0.566 & GMRES+ILU \\
100 & 0.007 & 0.630 & SPLU (fallback) \\
\bottomrule
\end{tabular}
\caption{Tempos de execução para diferentes valores de $k$}
\end{table}
\end{block}

\vspace{0.2cm}

\begin{block}{Observações}
\begin{itemize}
\item Tempo de build é desprezível comparado ao solve
\item GMRES+ILU é mais eficiente para sistemas grandes
\item Fallback para SPLU quando ILU falha (caso $k=100$)
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Otimizações Implementadas}
\begin{block}{Técnicas de Aceleração}
\begin{itemize}
\item \textbf{Cache de Matrizes}: Reutilização de matrizes Laplacianas (90\% mais rápido)
\item \textbf{Paralelização}: Processamento paralelo de casos independentes (3-4x mais rápido)
\item \textbf{Pré-aquecimento}: Construção prévia de estruturas necessárias
\item \textbf{Seleção Automática de Solver}: Escolha ótima entre SPLU e GMRES+ILU
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Ganhos Observados}
\begin{itemize}
\item \textbf{Cache}: Redução de 90\% no tempo de construção da matriz
\item \textbf{Paralelização}: Aceleração de 3-4x para múltiplos grupos
\item \textbf{Solver Adaptativo}: Uso de GMRES+ILU para sistemas grandes, SPLU para pequenos
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Visualizações - Superfície 3D ($k=20$, $N=128$)}
\begin{columns}
\begin{column}{0.5\textwidth}
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{figures/group_1/surf_k20_N128_real.pdf}
\caption{Solução numérica}
\end{figure}
\end{column}
\begin{column}{0.5\textwidth}
\begin{block}{Observações}
\begin{itemize}
\item Oscilações bem capturadas para $k=20$
\item Boa precisão com $N=128$
\item Erro relativo: $4.2 \times 10^{-2}$
\end{itemize}
\end{block}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Visualizações - Comparação Numérico vs Exato}
\begin{columns}
\begin{column}{0.5\textwidth}
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{figures/group_1/cut_x05_k20_N128_real.pdf}
\caption{Corte em $x=0.5$}
\end{figure}
\end{column}
\begin{column}{0.5\textwidth}
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{figures/group_1/cut_y05_k20_N128_real.pdf}
\caption{Corte em $y=0.5$}
\end{figure}
\end{column}
\end{columns}

\vspace{0.1cm}

\begin{block}{Análise}
\footnotesize
Excelente concordância entre solução numérica (linha azul) e exata (linha laranja) para $k=20$, $N=128$.
\end{block}
\end{frame}

\begin{frame}{Visualizações - Efeito da Poluição Numérica}
\begin{columns}
\begin{column}{0.5\textwidth}
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{figures/group_1/surf_k100_N256_real.pdf}
\caption{$k=100$, $N=256$}
\end{figure}
\end{column}
\begin{column}{0.5\textwidth}
\begin{block}{Comparação}
\footnotesize
\begin{itemize}
\item \textbf{$k=20$, $N=128$}: Erro $4.2 \times 10^{-2}$
\item \textbf{$k=100$, $N=256$}: Erro $3.6$ (poluição severa)
\item $N_{\lambda} \approx 16$ para $k=100$ (marginal)
\end{itemize}
\end{block}
\end{column}
\end{columns}
\end{frame}

% ============================================
% SEÇÃO 5: DISCUSSÃO
% ============================================
\section{Discussão}

\begin{frame}{Efeito de Poluição Numérica}
\begin{block}{Definição}
\textbf{Poluição Numérica}: Mesmo com refinamento de malha, o erro cresce com o aumento de $k$, devido à má representação da fase da onda.
\end{block}

\vspace{0.3cm}

\begin{block}{Mecanismo}
\begin{enumerate}
\item \textbf{Poucos pontos por comprimento de onda}: $N_{\lambda} < 20$
\item \textbf{Erro de fase}: Velocidade de fase numérica $\neq$ exata
\item \textbf{Acúmulo}: Erro se propaga e amplifica
\item \textbf{Resultado}: Solução numérica "atrasa" espacialmente
\end{enumerate}
\end{block}

\vspace{0.3cm}

\begin{block}{Consequência}
É necessário um número crescente de pontos por comprimento de onda para manter a precisão quando $k$ aumenta.
\end{block}
\end{frame}

\begin{frame}{Comparação com Literatura}
\begin{block}{Resultados Consistentes}
\begin{itemize}
\item \textbf{Ordem de convergência}: $p \approx 2.0$ para $k$ pequeno (conforme teoria)
\item \textbf{Requisito de malha}: $N_{\lambda} \geq 10-20$ (alinhado com literatura)
\item \textbf{Poluição numérica}: Observada para $kh$ grande (esperado)
\item \textbf{Erros relativos}: $10^{-4}$ para $k=1$ com $N=60$ (trabalho original)
\item \textbf{Erros relativos}: $10^{-7}$ a $10^{-8}$ para $k=1$ com $N \geq 128$ (extensão)
\end{itemize}
\end{block}

\vspace{0.2cm}

\begin{block}{Contribuições do Trabalho}
\begin{itemize}
\item Validação numérica completa (6 grupos, múltiplas malhas)
\item Análise sistemática da taxa de convergência
\item Implementação eficiente com matrizes esparsas
\item Análise do efeito de poluição numérica
\item Avaliação do uso de IA como ferramenta auxiliar
\end{itemize}
\end{block}
\end{frame}

% ============================================
% SEÇÃO 6: IA COMO FERRAMENTA
% ============================================
\section{Inteligência Artificial como Ferramenta Auxiliar}

\begin{frame}{Utilização da Inteligência Artificial}
\begin{block}{Ferramentas Utilizadas}
\begin{itemize}
\item \textbf{ChatGPT}: Suporte conceitual e sugestões metodológicas
\item \textbf{Gemini}: Análise comparativa e validação de abordagens
\item \textbf{NotebookLM}: Organização e síntese de informações
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Aplicações}
As IAs foram utilizadas como ferramentas de apoio:
\begin{itemize}
\item \textbf{Conceitual}: Esclarecimento de dúvidas teóricas
\item \textbf{Comparativa}: Validação de diferentes abordagens
\item \textbf{Metodológica}: Sugestões de implementação
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Comparação entre IAs}
\begin{block}{Critérios de Avaliação}
\begin{itemize}
\item \textbf{Sugestão de métodos}: Qualidade das recomendações numéricas
\item \textbf{Clareza teórica}: Explicações e fundamentação
\item \textbf{Custo computacional sugerido}: Análise de eficiência
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Resultados da Comparação}
\begin{table}[h]
\centering
\small
\begin{tabular}{lccc}
\toprule
IA & Métodos & Teoria & Custo \\
\midrule
ChatGPT & Boa & Excelente & Razoável \\
Gemini & Excelente & Boa & Boa \\
NotebookLM & Razoável & Boa & Razoável \\
\bottomrule
\end{tabular}
\caption{Comparação qualitativa entre IAs (exemplo)}
\end{table}
\end{block}

\vspace{0.2cm}

\begin{alertblock}{Nota}
A IA mostrou-se útil como suporte acadêmico, complementando o trabalho de pesquisa e implementação.
\end{alertblock}
\end{frame}

% ============================================
% SEÇÃO 7: CONCLUSÕES
% ============================================
\section{Conclusões}

\begin{frame}{Conclusões}
\begin{block}{Resultados Principais}
\begin{itemize}
\item O MDFC2 é adequado para baixos valores de $k$ ($k \leq 20$)
\item Taxa de convergência confirma ordem 2 para $k$ pequeno ($p \approx 2.0$)
\item O efeito de poluição numérica limita a eficiência para $k$ grande
\item Métodos de ordem superior reduzem esse efeito (perspectiva futura)
\item IA mostrou-se útil como suporte acadêmico
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Limitações Identificadas}
\begin{itemize}
\item \textbf{Poluição numérica}: Mesmo com refinamento, erro cresce com $k$ grande
\item \textbf{Requisito de malha}: Para $k=100$, necessário $N_{\lambda} \geq 20-30$ pontos/comprimento de onda
\item \textbf{Custo computacional}: Cresce com $N^2$ (sistemas grandes requerem métodos iterativos)
\item \textbf{Precisão limitada}: Erro relativo $> 1.0$ para $k=100$ com $N=60$
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Validação do Método}
\begin{block}{Conformidade com Teoria}
\begin{itemize}
\item \textbf{Consistência}: Erro de truncamento $O(h^2)$ confirmado numericamente
\item \textbf{Convergência}: Taxa experimental $p \approx 2.0$ para $k$ pequeno (conforme esperado)
\item \textbf{Estabilidade}: Sistema bem-condicionado para $k$ pequeno/médio
\item \textbf{Precisão}: Erros relativos da ordem de $10^{-7}$ a $10^{-8}$ para $k=1$
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Comparação com Literatura}
\begin{itemize}
\item Resultados consistentes com trabalhos sobre diferenças finitas para Helmholtz
\item Comportamento de poluição numérica observado conforme esperado
\item Requisitos de malha ($N_{\lambda} \geq 10-20$) alinhados com literatura
\item Taxa de convergência degradada para $k$ grande documentada
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Perspectivas Futuras}
\begin{block}{Melhorias Metodológicas}
\begin{itemize}
\item \textbf{Métodos de alta ordem}: 4ª ou 6ª ordem para reduzir poluição numérica
\item \textbf{Métodos híbridos}: Combinação de diferentes abordagens
\item \textbf{Malhas adaptativas}: Refinamento local onde necessário
\item \textbf{Pré-condicionadores especializados}: Otimizados para equação de Helmholtz
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Integração com IA}
\begin{itemize}
\item \textbf{IA + Métodos Numéricos}: Uso de IA para otimização de parâmetros
\item \textbf{Seleção automática de métodos}: IA sugere melhor método para cada caso
\item \textbf{Análise preditiva}: IA prevê comportamento numérico antes da execução
\end{itemize}
\end{block}

\vspace{0.3cm}

\begin{block}{Extensões}
\begin{itemize}
\item \textbf{Problemas 3D}: Generalização para domínios tridimensionais
\item \textbf{Condições de contorno avançadas}: Robin, Neumann, PML
\item \textbf{Comparação sistemática}: Elementos finitos, métodos espectrais
\end{itemize}
\end{block}
\end{frame}

% ============================================
% SLIDE FINAL
% ============================================
\begin{frame}
\begin{center}
\Huge Obrigado!

\vspace{1cm}

\Large Perguntas?
\end{center}
\end{frame}

\end{document}
